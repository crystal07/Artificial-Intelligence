{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import collections\n",
    "from math import log\n",
    "start_time = time.clock()\n",
    "\n",
    "classes = []\n",
    "\n",
    "with open(\"WordEmbedding.txt\") as words :\n",
    "    objects = words.read().split()\n",
    "    objects = [objects[i : i+2] for i in range(0, len(objects), 2)]\n",
    "\n",
    "words = []\n",
    "word_distance = []\n",
    "for i in objects :\n",
    "    i[1] = list(map(float, i[1].split(\",\")))\n",
    "    words.append(i[0])\n",
    "    word_distance.append(i[1])\n",
    "    \n",
    "threshold = [0.2, 0.4, 0.6, 0.8]\n",
    "cluster_similarity = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_matrix (classes) :\n",
    "    matrix = []\n",
    "    #item_set = []\n",
    "    for i in classes :\n",
    "        tmp = []\n",
    "        #item_set.append(i[0])\n",
    "        for j in classes :\n",
    "            if classes.index(i) < classes.index(j) :\n",
    "                continue\n",
    "            tmp.append(get_similarity(i, j))\n",
    "        matrix.append(tmp)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity (item_set_x, item_set_y) :\n",
    "    similarity_list = []\n",
    "    if item_set_x == item_set_y :\n",
    "        #return 0\n",
    "        return 1\n",
    "\n",
    "    for i in item_set_x :\n",
    "        for j in item_set_y :\n",
    "            # educlidean distance\n",
    "            #similarity_list.append(sum(list((i[1][index]-j[1][index])**2 for index in range(len(i[1]))))**0.5)\n",
    "            # cosine similarity\n",
    "            similarity_list.append(sum(list((i[1][index]*j[1][index]) for index in range(len(i[1]))))/((sum(list((i[1][indexi])**2 for indexi in range(len(i[1]))))**0.5)*(sum(list((j[1][indexj])**2 for indexj in range(len(j[1]))))**0.5)))\n",
    "    \n",
    "    if len(similarity_list) == 0 :\n",
    "        #return 0\n",
    "        return 1\n",
    "    else :\n",
    "        return min(similarity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minimum_similarity (matrix, classes) :\n",
    "    #min = 5000\n",
    "    min = -1\n",
    "    row = None\n",
    "    col = None\n",
    "    for i in matrix :\n",
    "        for j in i :\n",
    "            #if j < min and j != 0:\n",
    "            if j > min and j != 1:\n",
    "                min = j\n",
    "                row = matrix.index(i)\n",
    "                col = i.index(j)\n",
    "    return classes[row], classes[col], row, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_number (word, cluster) :\n",
    "    for i in cluster :\n",
    "        if word in i :\n",
    "            return cluster.index(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_matrix (matrix) :\n",
    "    for i in matrix:\n",
    "        for j in i:\n",
    "            print(j, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_row (matrix, row, col) :\n",
    "    matrix.pop(row)\n",
    "    matrix.pop(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_col (matrix, row, col) :\n",
    "    for i in matrix :\n",
    "        if len(i) > row :\n",
    "            i.pop(row)\n",
    "        if len(i) > col :\n",
    "            i.pop(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_new_class (matrix, new_class, classes) :\n",
    "    new_class_similarity = []\n",
    "    for i in classes :\n",
    "        #new_class_similarity.append((get_similarity(new_class, i)-min_val)/max_val)\n",
    "        new_class_similarity.append((get_similarity(new_class, i)))\n",
    "    matrix.append(new_class_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_set (list_content) :\n",
    "    set_content = set()\n",
    "    for i in list_content :\n",
    "        set_content.add(i[0])\n",
    "    return set_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy (result, topic_list) :\n",
    "    class_dict = {}\n",
    "    for i in topic_list.keys() :\n",
    "        class_dict[i] = []\n",
    "    \n",
    "    for i in result :\n",
    "        for topic, value in topic_list.items() :\n",
    "            for k in value :\n",
    "                if i == k :\n",
    "                    class_dict[topic].append(i)\n",
    "    \n",
    "    total = 0\n",
    "    for i in class_dict.values() :\n",
    "        total += len(i)\n",
    "    \n",
    "    entropy = 0\n",
    "    for i in class_dict.values() :\n",
    "        if len(i) == 0 :\n",
    "            continue\n",
    "        entropy -= (len(i)/total)*log((len(i)/total), 2)\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silhouette (result, others, words, word_distance) :  \n",
    "    a = []\n",
    "    b = []\n",
    "    s = []\n",
    "    for i in result :\n",
    "        if len(result) > 1 :\n",
    "            a.append(sum([get_distance(i, j, words, word_distance) for j in result if j != i]) / (len(result)-1))\n",
    "        else :\n",
    "            a.append(0)\n",
    "        if len(others) > 0 :\n",
    "            b.append(min([sum([get_distance(i, j, words, word_distance) for j in k if j != i]) / len(k) for k in others]))\n",
    "        else :\n",
    "            b.append(0)\n",
    "        if max(a[-1], b[-1]) != 0 :\n",
    "            s.append((b[-1]-a[-1])/max(a[-1], b[-1]))\n",
    "        else :\n",
    "            s.append(0)\n",
    "    return sum(s)/len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance (item_x, item_y, words, word_distance) :\n",
    "    return sum(list((word_distance[words.index(item_x)][index]-word_distance[words.index(item_y)][index])**2 for index in range(len(word_distance[words.index(item_x)]))))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in objects :\n",
    "    tmp = []\n",
    "    tmp.append(i)\n",
    "    classes.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = get_similarity_matrix(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = 0\n",
    "min_val = 5000\n",
    "for i in similarity_matrix :\n",
    "    if max(i) > max_val :\n",
    "        max_val = max(i)\n",
    "    if min(i) < min_val :\n",
    "        min_val = min(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(similarity_matrix)) :\n",
    "    for col in range(len(similarity_matrix[row])) :\n",
    "        #similarity_matrix[row][col] = (similarity_matrix[row][col] - min_val)/ max_val\n",
    "        similarity_matrix[row][col] = similarity_matrix[row][col]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similarity_dict = {}\n",
    "while len(classes) > 1 :\n",
    "    item_set_x, item_set_y, row, col = get_minimum_similarity(similarity_matrix, classes)\n",
    "    classes.remove(item_set_y)\n",
    "    classes.remove(item_set_x)\n",
    "    classes.append(item_set_x+item_set_y)\n",
    "    if similarity_matrix[row][col] in similarity_dict.keys() :\n",
    "        similarity_dict[similarity_matrix[row][col]].append([item_set_x+item_set_y])\n",
    "    else :\n",
    "        similarity_dict[similarity_matrix[row][col]] = [item_set_x+item_set_y]\n",
    "    delete_row(similarity_matrix, row, col)\n",
    "    delete_col(similarity_matrix, row, col)\n",
    "    append_new_class(similarity_matrix, list(item_set_x+item_set_y), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering complete time 183.50444000000002\n"
     ]
    }
   ],
   "source": [
    "print(\"calculation complete time\", time.clock()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity_dict = collections.OrderedDict(sorted(similarity_dict.items(), reverse=True))\n",
    "similarity_dict = collections.OrderedDict(sorted(similarity_dict.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_result = []\n",
    "for i in similarity_dict.keys() :\n",
    "    #if i <= threshold :\n",
    "    if i >= threshold :\n",
    "        for j in similarity_dict[i] :\n",
    "            duplicated = False\n",
    "            for k in clustered_result :\n",
    "                new_set = list_to_set(j)\n",
    "                if new_set.issubset(k) :\n",
    "                    duplicated = True\n",
    "                    break\n",
    "            if duplicated == False :\n",
    "                clustered_result.append(list_to_set(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in words :\n",
    "    exist = False\n",
    "    for j in clustered_result :\n",
    "        if i in j :\n",
    "            exist = True\n",
    "    if exist == False :\n",
    "        clustered_result.append([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "total 338\n"
     ]
    }
   ],
   "source": [
    "total_word = 0\n",
    "for i in clustered_result :\n",
    "    print(len(i))\n",
    "    total_word+=len(i)\n",
    "print(\"total\", total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "terrible\n",
      "dreadful\n",
      "2\n",
      "enraged\n",
      "infuriated\n",
      "3\n",
      "appalled\n",
      "disgusted\n",
      "4\n",
      "ecstatic\n",
      "elated\n",
      "overjoyed\n",
      "5\n",
      "thrilled\n",
      "delighted\n",
      "6\n",
      "thankful\n",
      "grateful\n",
      "7\n",
      "secret\n",
      "8\n",
      "confidential\n",
      "9\n",
      "controversial\n",
      "10\n",
      "underground\n",
      "11\n",
      "cover\n",
      "12\n",
      "forbidden\n",
      "13\n",
      "banned\n",
      "14\n",
      "agenda\n",
      "15\n",
      "insider\n",
      "16\n",
      "blacklisted\n",
      "17\n",
      "censored\n",
      "18\n",
      "concealed\n",
      "19\n",
      "confessions\n",
      "20\n",
      "unbelievable\n",
      "21\n",
      "covert\n",
      "22\n",
      "hidden\n",
      "23\n",
      "scoop\n",
      "24\n",
      "magical\n",
      "25\n",
      "instantly\n",
      "26\n",
      "missing\n",
      "27\n",
      "magnificent\n",
      "28\n",
      "miracle\n",
      "29\n",
      "important\n",
      "30\n",
      "profitable\n",
      "31\n",
      "proven\n",
      "32\n",
      "quick\n",
      "33\n",
      "remarkable\n",
      "34\n",
      "results\n",
      "35\n",
      "revolutionary\n",
      "36\n",
      "safe\n",
      "37\n",
      "save\n",
      "38\n",
      "sensational\n",
      "39\n",
      "should\n",
      "40\n",
      "startling\n",
      "41\n",
      "agree\n",
      "42\n",
      "recommend\n",
      "43\n",
      "suggest\n",
      "44\n",
      "superb\n",
      "45\n",
      "superior\n",
      "46\n",
      "tremendous\n",
      "47\n",
      "truly\n",
      "48\n",
      "trustworthy\n",
      "49\n",
      "urge\n",
      "50\n",
      "worthwhile\n",
      "51\n",
      "deadline\n",
      "52\n",
      "limited\n",
      "53\n",
      "seize\n",
      "54\n",
      "bargain\n",
      "55\n",
      "discount\n",
      "56\n",
      "explode\n",
      "57\n",
      "extra\n",
      "58\n",
      "fortune\n",
      "59\n",
      "freebie\n",
      "60\n",
      "jackpot\n",
      "61\n",
      "reduced\n",
      "62\n",
      "instant\n",
      "63\n",
      "skyrocket\n",
      "64\n",
      "immediately\n",
      "65\n",
      "doubtful\n",
      "66\n",
      "uncertain\n",
      "67\n",
      "indecisive\n",
      "68\n",
      "perplexed\n",
      "69\n",
      "embarrassed\n",
      "70\n",
      "hesitant\n",
      "71\n",
      "disillusioned\n",
      "72\n",
      "distrustful\n",
      "73\n",
      "misgiving\n",
      "74\n",
      "unsure\n",
      "75\n",
      "tense\n",
      "76\n",
      "stressed\n",
      "77\n",
      "uncomfortable\n",
      "78\n",
      "dishonest\n",
      "79\n",
      "disdainful\n",
      "80\n",
      "manipulative\n",
      "81\n",
      "judgmental\n",
      "82\n",
      "argumentative\n",
      "83\n",
      "authoritative\n",
      "84\n",
      "condescending\n",
      "85\n",
      "distracted\n",
      "86\n",
      "disoriented\n",
      "87\n",
      "frenzied\n",
      "88\n",
      "blushing\n",
      "89\n",
      "awkward\n",
      "90\n",
      "incapable\n",
      "91\n",
      "paralyzed\n",
      "92\n",
      "fatigued\n",
      "93\n",
      "inferior\n",
      "94\n",
      "vulnerable\n",
      "95\n",
      "distressed\n",
      "96\n",
      "pathetic\n",
      "97\n",
      "distraught\n",
      "98\n",
      "doomed\n",
      "99\n",
      "overwhelmed\n",
      "100\n",
      "incompetent\n",
      "101\n",
      "incapacitated\n",
      "102\n",
      "trapped\n",
      "103\n",
      "squirming\n",
      "104\n",
      "jittery\n",
      "105\n",
      "woozy\n",
      "106\n",
      "twitching\n",
      "107\n",
      "compulsive\n",
      "108\n",
      "uncaring\n",
      "109\n",
      "uninterested\n",
      "110\n",
      "unresponsive\n",
      "111\n",
      "terrified\n",
      "112\n",
      "suspicious\n",
      "113\n",
      "anxious\n",
      "114\n",
      "alarmed\n",
      "115\n",
      "panicked\n",
      "116\n",
      "threatened\n",
      "117\n",
      "cowardly\n",
      "118\n",
      "insecure\n",
      "119\n",
      "helplessness\n",
      "120\n",
      "disempowered\n",
      "121\n",
      "ordeal\n",
      "122\n",
      "outrageousness\n",
      "123\n",
      "provoke\n",
      "124\n",
      "repulsive\n",
      "125\n",
      "scandal\n",
      "126\n",
      "severe\n",
      "127\n",
      "shameful\n",
      "128\n",
      "shocking\n",
      "129\n",
      "tragic\n",
      "130\n",
      "unreliable\n",
      "131\n",
      "unstable\n",
      "132\n",
      "wicked\n",
      "133\n",
      "aggravate\n",
      "134\n",
      "agony\n",
      "135\n",
      "atrocious\n",
      "136\n",
      "corrupting\n",
      "137\n",
      "damaging\n",
      "138\n",
      "deplorable\n",
      "139\n",
      "disadvantages\n",
      "140\n",
      "disastrous\n",
      "141\n",
      "eliminate\n",
      "142\n",
      "harmful\n",
      "143\n",
      "harsh\n",
      "144\n",
      "inconsiderate\n",
      "145\n",
      "offensive\n",
      "146\n",
      "aggressive\n",
      "147\n",
      "frustrated\n",
      "148\n",
      "controlling\n",
      "149\n",
      "resentful\n",
      "150\n",
      "malicious\n",
      "151\n",
      "critical\n",
      "152\n",
      "violent\n",
      "153\n",
      "vindictive\n",
      "154\n",
      "sadistic\n",
      "155\n",
      "spiteful\n",
      "156\n",
      "furious\n",
      "157\n",
      "agitated\n",
      "158\n",
      "antagonistic\n",
      "159\n",
      "repulsed\n",
      "160\n",
      "quarrelsome\n",
      "161\n",
      "venomous\n",
      "162\n",
      "rebellious\n",
      "163\n",
      "exasperated\n",
      "164\n",
      "impatient\n",
      "165\n",
      "contrary\n",
      "166\n",
      "condemning\n",
      "167\n",
      "seething\n",
      "168\n",
      "scornful\n",
      "169\n",
      "sarcastic\n",
      "170\n",
      "poisonous\n",
      "171\n",
      "jealous\n",
      "172\n",
      "revengeful\n",
      "173\n",
      "retaliating\n",
      "174\n",
      "reprimanding\n",
      "175\n",
      "powerless\n",
      "176\n",
      "despicable\n",
      "177\n",
      "desperate\n",
      "178\n",
      "alienated\n",
      "179\n",
      "pessimistic\n",
      "180\n",
      "dejected\n",
      "181\n",
      "vilified\n",
      "182\n",
      "unjustified\n",
      "183\n",
      "violated\n",
      "184\n",
      "accurate\n",
      "185\n",
      "advantage\n",
      "186\n",
      "always\n",
      "187\n",
      "certainly\n",
      "188\n",
      "convenient\n",
      "189\n",
      "definitely\n",
      "190\n",
      "easy\n",
      "191\n",
      "emphasize\n",
      "192\n",
      "extremely\n",
      "193\n",
      "freedom\n",
      "194\n",
      "guaranteed\n",
      "195\n",
      "effective\n",
      "196\n",
      "introducing\n",
      "197\n",
      "investment\n",
      "198\n",
      "honored\n",
      "199\n",
      "adaptable\n",
      "200\n",
      "astonishing\n",
      "201\n",
      "astounded\n",
      "202\n",
      "secure\n",
      "203\n",
      "stable\n",
      "204\n",
      "honest\n",
      "205\n",
      "truthful\n",
      "206\n",
      "supportive\n",
      "207\n",
      "excellent\n",
      "208\n",
      "responsible\n",
      "209\n",
      "solid\n",
      "210\n",
      "absolutely\n",
      "211\n",
      "clarity\n",
      "212\n",
      "transparency\n",
      "213\n",
      "humility\n",
      "214\n",
      "blissful\n",
      "215\n",
      "joyous\n",
      "216\n",
      "gleeful\n",
      "217\n",
      "festive\n",
      "218\n",
      "satisfied\n",
      "219\n",
      "cheerful\n",
      "220\n",
      "sunny\n",
      "221\n",
      "jubilant\n",
      "222\n",
      "jovial\n",
      "223\n",
      "lighthearted\n",
      "224\n",
      "glorious\n",
      "225\n",
      "innocent\n",
      "226\n",
      "gratified\n",
      "227\n",
      "euphoric\n",
      "228\n",
      "world\n",
      "229\n",
      "playful\n",
      "230\n",
      "courageous\n",
      "231\n",
      "energetic\n",
      "232\n",
      "liberated\n",
      "233\n",
      "optimistic\n",
      "234\n",
      "frisky\n",
      "235\n",
      "animated\n",
      "236\n",
      "spirited\n",
      "237\n",
      "wonderful\n",
      "238\n",
      "funny\n",
      "239\n",
      "intelligent\n",
      "240\n",
      "exhilarated\n",
      "241\n",
      "spunky\n",
      "242\n",
      "youthful\n",
      "243\n",
      "vigorous\n",
      "244\n",
      "tickled\n",
      "245\n",
      "creative\n",
      "246\n",
      "constructive\n",
      "247\n",
      "helpful\n",
      "248\n",
      "resourceful\n",
      "249\n",
      "pleased\n",
      "250\n",
      "encouraged\n",
      "251\n",
      "surprised\n",
      "252\n",
      "content\n",
      "253\n",
      "blessed\n",
      "254\n",
      "vibrant\n",
      "255\n",
      "bountiful\n",
      "256\n",
      "glowing\n",
      "257\n",
      "motivated\n",
      "258\n",
      "eager\n",
      "259\n",
      "keen\n",
      "260\n",
      "earnest\n",
      "261\n",
      "inspired\n",
      "262\n",
      "enthusiastic\n",
      "263\n",
      "bold\n",
      "264\n",
      "brave\n",
      "265\n",
      "daring\n",
      "266\n",
      "hopeful\n",
      "267\n",
      "upbeat\n",
      "268\n",
      "assured\n",
      "269\n",
      "clear\n",
      "270\n",
      "balanced\n",
      "271\n",
      "fine\n",
      "272\n",
      "okay\n",
      "273\n",
      "adequate\n",
      "274\n",
      "forgiving\n",
      "275\n",
      "reliable\n",
      "276\n",
      "sure\n",
      "277\n",
      "unique\n",
      "278\n",
      "dynamic\n",
      "279\n",
      "tenacious\n",
      "280\n",
      "cooperative\n",
      "281\n",
      "productive\n",
      "282\n",
      "exuberant\n",
      "283\n",
      "responsive\n",
      "284\n",
      "conscientious\n",
      "285\n",
      "approving\n",
      "286\n",
      "privileged\n",
      "287\n",
      "empowered\n",
      "288\n",
      "focused\n",
      "289\n",
      "capable\n",
      "290\n",
      "calm\n",
      "291\n",
      "comfortable\n",
      "292\n",
      "quiet\n",
      "293\n",
      "certain\n",
      "294\n",
      "relaxed\n",
      "295\n",
      "serene\n",
      "296\n",
      "bright\n",
      "297\n",
      "carefree\n",
      "298\n",
      "fulfilled\n",
      "299\n",
      "genuine\n",
      "300\n",
      "authentic\n",
      "301\n",
      "sincere\n",
      "302\n",
      "uplifted\n",
      "303\n",
      "unburdened\n",
      "304\n",
      "confident\n",
      "305\n",
      "radiant\n",
      "306\n",
      "beaming\n",
      "307\n",
      "reflective\n",
      "308\n",
      "smiling\n",
      "309\n",
      "grounded\n",
      "310\n",
      "unhurried\n",
      "311\n",
      "efficient\n",
      "312\n",
      "unassuming\n",
      "313\n",
      "trusting\n",
      "314\n",
      "supported\n",
      "315\n",
      "fluid\n",
      "316\n",
      "light\n",
      "317\n",
      "spontaneous\n",
      "318\n",
      "aware\n",
      "319\n",
      "healthy\n",
      "320\n",
      "meditative\n",
      "321\n",
      "still\n",
      "322\n",
      "rested\n",
      "323\n",
      "waiting\n",
      "324\n",
      "laughing\n",
      "325\n",
      "graceful\n",
      "326\n",
      "natural\n",
      "327\n",
      "steady\n",
      "328\n",
      "centered\n",
      "329\n",
      "placid\n",
      "330\n",
      "stoic\n",
      "331\n",
      "aligned\n",
      "total : 331\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in clustered_result :\n",
    "    count += 1\n",
    "    print(count)\n",
    "    for j in i :\n",
    "        print(j)\n",
    "\n",
    "print(\"total :\", len(clustered_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"clustering complete time\", time.clock()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cluster_similarity+\"_with_threshold_\"+str(threshold)+\".txt\", \"w\") as output :\n",
    "    for i in range(len(words)) :\n",
    "        output.write(\"{}\\n{}\\n{}\\n\".format(words[i], word_distance[i], get_cluster_number(words[i], clustered_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"WordTopic.txt\") as result :\n",
    "    topic = result.read().splitlines()\n",
    "    topic_list = {}\n",
    "    for i in topic :\n",
    "        if len(i) == 0 :\n",
    "            continue\n",
    "        if i[0] == '[' :\n",
    "            topic_list[i[1:-1]] = []\n",
    "            continue\n",
    "        topic_list[list(topic_list.keys())[-1]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005917159763313609\n"
     ]
    }
   ],
   "source": [
    "entropy_list = []\n",
    "total = 0\n",
    "for i in clustered_result :\n",
    "    total += len(i)\n",
    "    entropy_list.append(get_entropy(i, topic_list)*len(i))\n",
    "\n",
    "for i in range(len(entropy_list)) :\n",
    "    entropy_list[i] = entropy_list[i]/total\n",
    "\n",
    "new_entropy = sum(entropy_list)\n",
    "print(new_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0029354157703961135\n"
     ]
    }
   ],
   "source": [
    "silhouette_list = []\n",
    "total = 0\n",
    "for i in clustered_result :\n",
    "    total += len(i)\n",
    "    silhouette_list.append(get_silhouette(i, clustered_result[0:clustered_result.index(i)]+clustered_result[clustered_result.index(i)+1:-1], words, word_distance)*len(i))\n",
    "\n",
    "for i in range(len(silhouette_list)) :\n",
    "    silhouette_list[i] = silhouette_list[i]/total\n",
    "\n",
    "if len(silhouette_list) > 0 :\n",
    "    new_silhouette = sum(silhouette_list) / len(silhouette_list)\n",
    "    print(new_silhouette)\n",
    "else :\n",
    "    print(silhouette_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
