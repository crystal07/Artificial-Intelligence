{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import collections\n",
    "from math import log\n",
    "start_time = time.clock()\n",
    "\n",
    "classes = []\n",
    "\n",
    "with open(\"WordEmbedding.txt\") as words :\n",
    "    objects = words.read().split()\n",
    "    objects = [objects[i : i+2] for i in range(0, len(objects), 2)]\n",
    "\n",
    "words = []\n",
    "word_distance = []\n",
    "for i in objects :\n",
    "    i[1] = list(map(float, i[1].split(\",\")))\n",
    "    words.append(i[0])\n",
    "    word_distance.append(i[1])\n",
    "    \n",
    "threshold = [0.2, 0.4, 0.6, 0.8]\n",
    "cluster_similarity = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_matrix (classes) :\n",
    "    matrix = []\n",
    "    #item_set = []\n",
    "    for i in classes :\n",
    "        tmp = []\n",
    "        #item_set.append(i[0])\n",
    "        for j in classes :\n",
    "            if classes.index(i) < classes.index(j) :\n",
    "                continue\n",
    "            tmp.append(get_similarity(i, j))\n",
    "        matrix.append(tmp)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity (item_set_x, item_set_y) :\n",
    "    similarity_list = []\n",
    "    if item_set_x == item_set_y :\n",
    "        #return 0\n",
    "        return 1\n",
    "\n",
    "    for i in item_set_x :\n",
    "        for j in item_set_y :\n",
    "            # educlidean distance\n",
    "            #similarity_list.append(sum(list((i[1][index]-j[1][index])**2 for index in range(len(i[1]))))**0.5)\n",
    "            # cosine similarity\n",
    "            similarity_list.append(sum(list((i[1][index]*j[1][index]) for index in range(len(i[1]))))/((sum(list((i[1][indexi])**2 for indexi in range(len(i[1]))))**0.5)*(sum(list((j[1][indexj])**2 for indexj in range(len(j[1]))))**0.5)))\n",
    "    \n",
    "    if len(similarity_list) == 0 :\n",
    "        #return 0\n",
    "        return 1\n",
    "    else :\n",
    "        return min(similarity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minimum_similarity (matrix, classes) :\n",
    "    #min = 5000\n",
    "    min = -1\n",
    "    row = None\n",
    "    col = None\n",
    "    for i in matrix :\n",
    "        for j in i :\n",
    "            #if j < min and j != 0:\n",
    "            if j > min and j != 1:\n",
    "                min = j\n",
    "                row = matrix.index(i)\n",
    "                col = i.index(j)\n",
    "    return classes[row], classes[col], row, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_number (word, cluster) :\n",
    "    for i in cluster :\n",
    "        if word in i :\n",
    "            return cluster.index(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_matrix (matrix) :\n",
    "    for i in matrix:\n",
    "        for j in i:\n",
    "            print(j, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_row (matrix, row, col) :\n",
    "    matrix.pop(row)\n",
    "    matrix.pop(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_col (matrix, row, col) :\n",
    "    for i in matrix :\n",
    "        if len(i) > row :\n",
    "            i.pop(row)\n",
    "        if len(i) > col :\n",
    "            i.pop(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_new_class (matrix, new_class, classes) :\n",
    "    new_class_similarity = []\n",
    "    for i in classes :\n",
    "        #new_class_similarity.append((get_similarity(new_class, i)-min_val)/max_val)\n",
    "        new_class_similarity.append((get_similarity(new_class, i)))\n",
    "    matrix.append(new_class_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_set (list_content) :\n",
    "    set_content = set()\n",
    "    for i in list_content :\n",
    "        set_content.add(i[0])\n",
    "    return set_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy (result, topic_list) :\n",
    "    class_dict = {}\n",
    "    for i in topic_list.keys() :\n",
    "        class_dict[i] = []\n",
    "    \n",
    "    for i in result :\n",
    "        for topic, value in topic_list.items() :\n",
    "            for k in value :\n",
    "                if i == k :\n",
    "                    class_dict[topic].append(i)\n",
    "    \n",
    "    total = 0\n",
    "    for i in class_dict.values() :\n",
    "        total += len(i)\n",
    "    \n",
    "    entropy = 0\n",
    "    for i in class_dict.values() :\n",
    "        if len(i) == 0 :\n",
    "            continue\n",
    "        entropy -= (len(i)/total)*log((len(i)/total), 2)\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silhouette (result, others, words, word_distance) :  \n",
    "    a = []\n",
    "    b = []\n",
    "    s = []\n",
    "    for i in result :\n",
    "        if len(result) > 1 :\n",
    "            a.append(sum([get_distance(i, j, words, word_distance) for j in result if j != i]) / (len(result)-1))\n",
    "        else :\n",
    "            a.append(0)\n",
    "        if len(others) > 0 :\n",
    "            b.append(min([sum([get_distance(i, j, words, word_distance) for j in k if j != i]) / len(k) for k in others]))\n",
    "        else :\n",
    "            b.append(0)\n",
    "        if max(a[-1], b[-1]) != 0 :\n",
    "            s.append((b[-1]-a[-1])/max(a[-1], b[-1]))\n",
    "        else :\n",
    "            s.append(0)\n",
    "    return sum(s)/len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance (item_x, item_y, words, word_distance) :\n",
    "    return sum(list((word_distance[words.index(item_x)][index]-word_distance[words.index(item_y)][index])**2 for index in range(len(word_distance[words.index(item_x)]))))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in objects :\n",
    "    tmp = []\n",
    "    tmp.append(i)\n",
    "    classes.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = get_similarity_matrix(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = 0\n",
    "min_val = 5000\n",
    "for i in similarity_matrix :\n",
    "    if max(i) > max_val :\n",
    "        max_val = max(i)\n",
    "    if min(i) < min_val :\n",
    "        min_val = min(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(similarity_matrix)) :\n",
    "    for col in range(len(similarity_matrix[row])) :\n",
    "        #similarity_matrix[row][col] = (similarity_matrix[row][col] - min_val)/ max_val\n",
    "        similarity_matrix[row][col] = similarity_matrix[row][col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similarity_dict = {}\n",
    "while len(classes) > 1 :\n",
    "    item_set_x, item_set_y, row, col = get_minimum_similarity(similarity_matrix, classes)\n",
    "    classes.remove(item_set_y)\n",
    "    classes.remove(item_set_x)\n",
    "    classes.append(item_set_x+item_set_y)\n",
    "    if similarity_matrix[row][col] in similarity_dict.keys() :\n",
    "        similarity_dict[similarity_matrix[row][col]].append([item_set_x+item_set_y])\n",
    "    else :\n",
    "        similarity_dict[similarity_matrix[row][col]] = [item_set_x+item_set_y]\n",
    "    delete_row(similarity_matrix, row, col)\n",
    "    delete_col(similarity_matrix, row, col)\n",
    "    append_new_class(similarity_matrix, list(item_set_x+item_set_y), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculation complete time 180.790527\n"
     ]
    }
   ],
   "source": [
    "print(\"calculation complete time\", time.clock()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity_dict = collections.OrderedDict(sorted(similarity_dict.items(), reverse=True))\n",
    "similarity_dict = collections.OrderedDict(sorted(similarity_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'float' and 'list'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8d36ae3bb407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilarity_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#if i <= threshold :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilarity_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mduplicated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'float' and 'list'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "clustered_result = []\n",
    "for i in similarity_dict.keys() :\n",
    "    #if i <= threshold :\n",
    "    if i >= threshold :\n",
    "        for j in similarity_dict[i] :\n",
    "            duplicated = False\n",
    "            for k in clustered_result :\n",
    "                new_set = list_to_set(j)\n",
    "                if new_set.issubset(k) :\n",
    "                    duplicated = True\n",
    "                    break\n",
    "            if duplicated == False :\n",
    "                clustered_result.append(list_to_set(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in words :\n",
    "    exist = False\n",
    "    for j in clustered_result :\n",
    "        if i in j :\n",
    "            exist = True\n",
    "    if exist == False :\n",
    "        clustered_result.append([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word = 0\n",
    "for i in clustered_result :\n",
    "    print(len(i))\n",
    "    total_word+=len(i)\n",
    "print(\"total\", total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in clustered_result :\n",
    "    count += 1\n",
    "    print(count)\n",
    "    for j in i :\n",
    "        print(j)\n",
    "\n",
    "print(\"total :\", len(clustered_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"clustering complete time\", time.clock()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cluster_similarity+\"_with_threshold_\"+str(threshold)+\".txt\", \"w\") as output :\n",
    "    for i in range(len(words)) :\n",
    "        output.write(\"{}\\n{}\\n{}\\n\".format(words[i], word_distance[i], get_cluster_number(words[i], clustered_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"WordTopic.txt\") as result :\n",
    "    topic = result.read().splitlines()\n",
    "    topic_list = {}\n",
    "    for i in topic :\n",
    "        if len(i) == 0 :\n",
    "            continue\n",
    "        if i[0] == '[' :\n",
    "            topic_list[i[1:-1]] = []\n",
    "            continue\n",
    "        topic_list[list(topic_list.keys())[-1]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entropy_list = []\n",
    "total = 0\n",
    "for i in clustered_result :\n",
    "    total += len(i)\n",
    "    entropy_list.append(get_entropy(i, topic_list)*len(i))\n",
    "\n",
    "for i in range(len(entropy_list)) :\n",
    "    entropy_list[i] = entropy_list[i]/total\n",
    "\n",
    "new_entropy = sum(entropy_list)\n",
    "print(new_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_list = []\n",
    "total = 0\n",
    "for i in clustered_result :\n",
    "    total += len(i)\n",
    "    silhouette_list.append(get_silhouette(i, clustered_result[0:clustered_result.index(i)]+clustered_result[clustered_result.index(i)+1:-1], words, word_distance)*len(i))\n",
    "\n",
    "for i in range(len(silhouette_list)) :\n",
    "    silhouette_list[i] = silhouette_list[i]/total\n",
    "\n",
    "if len(silhouette_list) > 0 :\n",
    "    new_silhouette = sum(silhouette_list) / len(silhouette_list)\n",
    "    print(new_silhouette)\n",
    "else :\n",
    "    print(silhouette_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}